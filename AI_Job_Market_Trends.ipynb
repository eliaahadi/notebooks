{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 13124110,
          "sourceType": "datasetVersion",
          "datasetId": 8313727
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliaahadi/notebooks/blob/main/AI_Job_Market_Trends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "abhishekjaiswal4896_ai_job_market_trends_path = kagglehub.dataset_download('abhishekjaiswal4896/ai-job-market-trends')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "mSa_J5heNnPB",
        "outputId": "3674bf9d-b1d4-4055-b843-cc6c0ff8c73e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/abhishekjaiswal4896/ai-job-market-trends?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91.8k/91.8k [00:00<00:00, 29.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import xgboost as xgb\n",
        "from tabulate import tabulate\n",
        "\n",
        "# display settings\n",
        "sns.set(style='whitegrid', palette='muted', color_codes=True)\n",
        "\n",
        "# predictive modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# set random seed\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:50.717488Z",
          "iopub.execute_input": "2025-11-05T19:33:50.717705Z",
          "iopub.status.idle": "2025-11-05T19:33:52.442245Z",
          "shell.execute_reply.started": "2025-11-05T19:33:50.717688Z",
          "shell.execute_reply": "2025-11-05T19:33:52.441173Z"
        },
        "id": "F_tX8XbYNnPD"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/ai-job-market-trends/ai_job_market.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.443425Z",
          "iopub.execute_input": "2025-11-05T19:33:52.443811Z",
          "iopub.status.idle": "2025-11-05T19:33:52.495447Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.443786Z",
          "shell.execute_reply": "2025-11-05T19:33:52.494539Z"
        },
        "id": "LalX5urMNnPE",
        "outputId": "cd15ea45-c311-4145-8e14-2cbba31645cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/ai-job-market-trends/ai_job_market.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4288606602.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/ai-job-market-trends/ai_job_market.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ai-job-market-trends/ai_job_market.csv'"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.495963Z",
          "iopub.execute_input": "2025-11-05T19:33:52.496174Z",
          "iopub.status.idle": "2025-11-05T19:33:52.505669Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.49616Z",
          "shell.execute_reply": "2025-11-05T19:33:52.504989Z"
        },
        "id": "VHZkeMNBNnPE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.506297Z",
          "iopub.execute_input": "2025-11-05T19:33:52.506889Z",
          "iopub.status.idle": "2025-11-05T19:33:52.527465Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.50687Z",
          "shell.execute_reply": "2025-11-05T19:33:52.526734Z"
        },
        "id": "GDda0fHkNnPE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.529187Z",
          "iopub.execute_input": "2025-11-05T19:33:52.529387Z",
          "iopub.status.idle": "2025-11-05T19:33:52.556867Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.529371Z",
          "shell.execute_reply": "2025-11-05T19:33:52.55578Z"
        },
        "id": "vmMbboIENnPE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.55749Z",
          "iopub.execute_input": "2025-11-05T19:33:52.557711Z",
          "iopub.status.idle": "2025-11-05T19:33:52.577739Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.557695Z",
          "shell.execute_reply": "2025-11-05T19:33:52.576815Z"
        },
        "id": "hYIHPJuPNnPE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T.plot(kind='bar')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.578578Z",
          "iopub.execute_input": "2025-11-05T19:33:52.578803Z",
          "iopub.status.idle": "2025-11-05T19:33:52.895758Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.578783Z",
          "shell.execute_reply": "2025-11-05T19:33:52.895077Z"
        },
        "id": "hBqK9ftfNnPF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Distribution plot for each numerical column\n",
        "for col in numeric_cols:\n",
        "    sns.histplot(x=col, data=df, kde=True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:52.896521Z",
          "iopub.execute_input": "2025-11-05T19:33:52.896831Z",
          "iopub.status.idle": "2025-11-05T19:33:53.144462Z",
          "shell.execute_reply.started": "2025-11-05T19:33:52.896809Z",
          "shell.execute_reply": "2025-11-05T19:33:53.143463Z"
        },
        "id": "yluug-4iNnPF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 1: Countplot of Industry Distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(data=df, y='industry', order=df['industry'].value_counts().index)\n",
        "plt.title('Number of Job Listings per Industry')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Industry')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Countplot of Employment Type\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df, x='employment_type', order=df['employment_type'].value_counts().index)\n",
        "plt.title('Distribution of Employment Types')\n",
        "plt.xlabel('Employment Type')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 3: Histogram of Posted Dates\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['posted_date'].dropna(), bins=30, kde=False)\n",
        "plt.title('Distribution of Job Posting Dates')\n",
        "plt.xlabel('Posted Date')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# If the dataset had more numeric columns, we could create a correlation heatmap.\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "if numeric_df.shape[1] >= 4:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    corr = numeric_df.corr()\n",
        "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title('Correlation Heatmap of Numeric Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Not enough numeric features for a correlation heatmap.')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:53.145274Z",
          "iopub.execute_input": "2025-11-05T19:33:53.14547Z",
          "iopub.status.idle": "2025-11-05T19:33:59.261643Z",
          "shell.execute_reply.started": "2025-11-05T19:33:53.145455Z",
          "shell.execute_reply": "2025-11-05T19:33:59.260867Z"
        },
        "id": "EeYP5VbTNnPF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# For the predictive model, we will use a subset of features that we suspect have predictive power for 'experience_level'.\n",
        "# Selected features: 'industry', 'employment_type', 'company_size'\n",
        "\n",
        "# Check that the target and the features exist in the dataset\n",
        "selected_features = ['industry', 'employment_type', 'company_size']\n",
        "\n",
        "if all([col in df.columns for col in selected_features + ['experience_level']]):\n",
        "    model_df = df[selected_features + ['experience_level']].copy()\n",
        "\n",
        "    # Drop rows with missing values in these columns\n",
        "    model_df.dropna(inplace=True)\n",
        "\n",
        "    # Encoding categorical features using pandas' factorize method\n",
        "    for col in selected_features + ['experience_level']:\n",
        "        model_df[col] = pd.factorize(model_df[col])[0]\n",
        "\n",
        "    # Split data into training and testing sets (80/20 split)\n",
        "    X = model_df[selected_features]\n",
        "    y = model_df['experience_level']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Instantiate and train a RandomForestClassifier\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = rf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print('Prediction Accuracy:', accuracy)\n",
        "    print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix for Experience Level Prediction')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Permutation Importance Plot (simple bar plot for feature importances)\n",
        "    importances = rf.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "    plt.yticks(range(len(indices)), [selected_features[i] for i in indices])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title('Permutation Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print('Required columns for predictive modeling are missing from the dataset.')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-05T19:33:59.262149Z",
          "iopub.execute_input": "2025-11-05T19:33:59.262294Z",
          "iopub.status.idle": "2025-11-05T19:33:59.942519Z",
          "shell.execute_reply.started": "2025-11-05T19:33:59.262282Z",
          "shell.execute_reply": "2025-11-05T19:33:59.941693Z"
        },
        "id": "k1-6NygHNnPF"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}